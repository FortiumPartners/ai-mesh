# Task 6.4: ELK Stack Deployment for Log Aggregation and Analysis
# Helm Chart Specialist - Sprint 6 Observability Implementation
# Complete ELK Stack with Elasticsearch, Logstash, Kibana, and Filebeat

apiVersion: v1
kind: Namespace
metadata:
  name: elk-system
  labels:
    name: elk-system
    app: elk-stack

---
# Elasticsearch Deployment
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: elk-system
  labels:
    app: elasticsearch
    component: data
spec:
  serviceName: elasticsearch
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9200"
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      initContainers:
      - name: increase-vm-max-map
        image: busybox:1.35
        imagePullPolicy: IfNotPresent
        securityContext:
          privileged: true
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
      - name: increase-fd-ulimit
        image: busybox:1.35
        imagePullPolicy: IfNotPresent
        securityContext:
          privileged: true
        command: ["sh", "-c", "ulimit -n 65536"]
      containers:
      - name: elasticsearch
        image: docker.elastic.co/elasticsearch/elasticsearch:8.10.4
        env:
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: cluster.name
          value: "helm-chart-specialist-logs"
        - name: discovery.seed_hosts
          value: "elasticsearch-0.elasticsearch,elasticsearch-1.elasticsearch,elasticsearch-2.elasticsearch"
        - name: cluster.initial_master_nodes
          value: "elasticsearch-0,elasticsearch-1,elasticsearch-2"
        - name: ES_JAVA_OPTS
          value: "-Xmx2g -Xms2g"
        - name: xpack.security.enabled
          value: "false"
        - name: xpack.security.enrollment.enabled
          value: "false"
        - name: xpack.license.self_generated.type
          value: "basic"
        - name: network.host
          value: "0.0.0.0"
        - name: http.port
          value: "9200"
        - name: transport.port
          value: "9300"
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: elasticsearch-data
          mountPath: /usr/share/elasticsearch/data
        - name: elasticsearch-config
          mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          subPath: elasticsearch.yml
          readOnly: true
        resources:
          requests:
            memory: 3Gi
            cpu: 1000m
          limits:
            memory: 4Gi
            cpu: 2000m
        livenessProbe:
          httpGet:
            path: /_cluster/health
            port: 9200
          initialDelaySeconds: 90
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /_cluster/health?wait_for_status=yellow&timeout=5s
            port: 9200
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
      volumes:
      - name: elasticsearch-config
        configMap:
          name: elasticsearch-config
  volumeClaimTemplates:
  - metadata:
      name: elasticsearch-data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: gp3
      resources:
        requests:
          storage: 50Gi

---
# Elasticsearch Service
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch
  namespace: elk-system
  labels:
    app: elasticsearch
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9200"
spec:
  selector:
    app: elasticsearch
  ports:
  - name: http
    port: 9200
    targetPort: 9200
  - name: transport
    port: 9300
    targetPort: 9300
  clusterIP: None

---
# Elasticsearch External Service
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch-external
  namespace: elk-system
  labels:
    app: elasticsearch
spec:
  selector:
    app: elasticsearch
  ports:
  - name: http
    port: 9200
    targetPort: 9200
  type: ClusterIP

---
# Elasticsearch Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: elasticsearch-config
  namespace: elk-system
data:
  elasticsearch.yml: |
    cluster.name: "helm-chart-specialist-logs"
    network.host: 0.0.0.0
    http.port: 9200
    transport.port: 9300

    # Cluster settings
    discovery.zen.minimum_master_nodes: 2
    discovery.zen.ping.multicast.enabled: false
    discovery.zen.ping.unicast.hosts: ["elasticsearch-0.elasticsearch", "elasticsearch-1.elasticsearch", "elasticsearch-2.elasticsearch"]

    # Index settings for Helm Chart logs
    index:
      number_of_shards: 3
      number_of_replicas: 1
      refresh_interval: 5s

    # Memory settings
    bootstrap.memory_lock: true

    # Security (disabled for development)
    xpack.security.enabled: false
    xpack.security.enrollment.enabled: false

    # Monitoring
    xpack.monitoring.collection.enabled: true

    # Index lifecycle management
    ilm.policy.helm-logs-policy:
      policy:
        phases:
          hot:
            actions:
              rollover:
                max_size: 10gb
                max_age: 1d
          warm:
            min_age: 7d
            actions:
              allocate:
                number_of_replicas: 0
          cold:
            min_age: 30d
            actions:
              allocate:
                number_of_replicas: 0
          delete:
            min_age: 90d

---
# Kibana Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: elk-system
  labels:
    app: kibana
spec:
  replicas: 2
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: kibana
        image: docker.elastic.co/kibana/kibana:8.10.4
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch-external:9200"
        - name: SERVER_NAME
          value: "kibana"
        - name: SERVER_HOST
          value: "0.0.0.0"
        - name: SERVER_PORT
          value: "5601"
        - name: XPACK_SECURITY_ENABLED
          value: "false"
        - name: XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY
          value: "fhjsunxl7cxcbgbnslakhkhncplwqwer"
        ports:
        - containerPort: 5601
          name: ui
        volumeMounts:
        - name: kibana-config
          mountPath: /usr/share/kibana/config/kibana.yml
          subPath: kibana.yml
          readOnly: true
        resources:
          requests:
            memory: 1Gi
            cpu: 500m
          limits:
            memory: 2Gi
            cpu: 1000m
        livenessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/status
            port: 5601
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
      volumes:
      - name: kibana-config
        configMap:
          name: kibana-config

---
# Kibana Service
apiVersion: v1
kind: Service
metadata:
  name: kibana
  namespace: elk-system
  labels:
    app: kibana
spec:
  selector:
    app: kibana
  ports:
  - name: ui
    port: 5601
    targetPort: 5601
  type: ClusterIP

---
# Kibana Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: kibana-config
  namespace: elk-system
data:
  kibana.yml: |
    server.name: "kibana"
    server.host: "0.0.0.0"
    server.port: 5601

    elasticsearch.hosts: ["http://elasticsearch-external:9200"]
    elasticsearch.username: ""
    elasticsearch.password: ""

    # Security
    xpack.security.enabled: false
    xpack.encryptedSavedObjects.encryptionKey: "fhjsunxl7cxcbgbnslakhkhncplwqwer"

    # Monitoring
    xpack.monitoring.ui.container.elasticsearch.enabled: true

    # Default index patterns
    kibana.defaultAppId: "discover"

    # Logging
    logging.dest: stdout
    logging.level: info

    # Performance
    elasticsearch.requestTimeout: 30000
    elasticsearch.shardTimeout: 30000

    # Default index patterns for Helm Chart logs
    saved_objects:
      - type: index-pattern
        id: helm-chart-specialist-*
        attributes:
          title: "helm-chart-specialist-*"
          timeFieldName: "timestamp"

---
# Logstash Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  namespace: elk-system
  labels:
    app: logstash
spec:
  replicas: 3
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9600"
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:8.10.4
        env:
        - name: LS_JAVA_OPTS
          value: "-Xmx2g -Xms2g"
        - name: XPACK_MONITORING_ENABLED
          value: "true"
        - name: XPACK_MONITORING_ELASTICSEARCH_HOSTS
          value: "http://elasticsearch-external:9200"
        ports:
        - containerPort: 5044
          name: beats
        - containerPort: 9600
          name: http
        volumeMounts:
        - name: logstash-config
          mountPath: /usr/share/logstash/config/logstash.yml
          subPath: logstash.yml
          readOnly: true
        - name: logstash-pipeline
          mountPath: /usr/share/logstash/pipeline
          readOnly: true
        - name: logstash-templates
          mountPath: /usr/share/logstash/templates
          readOnly: true
        resources:
          requests:
            memory: 2Gi
            cpu: 1000m
          limits:
            memory: 3Gi
            cpu: 2000m
        livenessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 9600
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
      volumes:
      - name: logstash-config
        configMap:
          name: logstash-config
      - name: logstash-pipeline
        configMap:
          name: logstash-pipeline
      - name: logstash-templates
        configMap:
          name: logstash-templates

---
# Logstash Service
apiVersion: v1
kind: Service
metadata:
  name: logstash
  namespace: elk-system
  labels:
    app: logstash
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9600"
spec:
  selector:
    app: logstash
  ports:
  - name: beats
    port: 5044
    targetPort: 5044
  - name: http
    port: 9600
    targetPort: 9600
  type: ClusterIP

---
# Logstash Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
  namespace: elk-system
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    http.port: 9600

    # Performance tuning
    pipeline.workers: 4
    pipeline.batch.size: 1000
    pipeline.batch.delay: 50

    # Monitoring
    xpack.monitoring.enabled: true
    xpack.monitoring.elasticsearch.hosts: ["http://elasticsearch-external:9200"]

    # Logging
    log.level: info
    log.format: json

---
# Logstash Pipeline Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-pipeline
  namespace: elk-system
data:
  helm-chart-logs.conf: |
    input {
      beats {
        port => 5044
        host => "0.0.0.0"
      }

      http {
        port => 8080
        host => "0.0.0.0"
        codec => json
      }
    }

    filter {
      # Parse JSON logs
      if [message] =~ /^\{.*\}$/ {
        json {
          source => "message"
        }
      }

      # Add correlation fields
      if [correlationId] {
        mutate {
          add_field => { "correlation_id" => "%{correlationId}" }
        }
      }

      if [traceId] {
        mutate {
          add_field => { "trace_id" => "%{traceId}" }
        }
      }

      # Parse Helm Chart specific fields
      if [operation] {
        mutate {
          add_field => { "helm_operation" => "%{operation}" }
          add_tag => [ "helm-operation" ]
        }
      }

      if [chartType] {
        mutate {
          add_field => { "chart_type" => "%{chartType}" }
        }
      }

      if [environment_target] {
        mutate {
          add_field => { "target_environment" => "%{environment_target}" }
        }
      }

      # Security log processing
      if "security" in [tags] {
        mutate {
          add_tag => [ "security-event" ]
        }

        # Extract security indicators
        if [indicators] {
          mutate {
            add_field => { "security_indicators" => "%{indicators}" }
          }
        }
      }

      # Performance log processing
      if "performance" in [tags] {
        mutate {
          add_tag => [ "performance-metric" ]
        }

        # Convert duration to numeric
        if [duration] {
          mutate {
            convert => { "duration" => "integer" }
          }
        }
      }

      # Business log processing
      if "business" in [tags] {
        mutate {
          add_tag => [ "business-event" ]
        }
      }

      # Audit log processing
      if "audit" in [tags] {
        mutate {
          add_tag => [ "audit-event" ]
          add_field => { "audit_immutable" => "true" }
        }
      }

      # Error detection and enrichment
      if [level] == "error" or "error" in [tags] {
        mutate {
          add_tag => [ "error-event" ]
        }

        # Extract error details
        if [error] {
          grok {
            match => { "error" => "%{GREEDYDATA:error_message}" }
          }
        }
      }

      # Add processing timestamp
      mutate {
        add_field => { "processed_at" => "%{@timestamp}" }
      }

      # Geoip for IP addresses (if present)
      if [ip_address] {
        geoip {
          source => "ip_address"
          target => "geoip"
        }
      }

      # Date parsing
      date {
        match => [ "timestamp", "ISO8601" ]
        target => "@timestamp"
      }
    }

    output {
      # Main Elasticsearch output
      elasticsearch {
        hosts => ["http://elasticsearch-external:9200"]
        index => "helm-chart-specialist-%{+YYYY.MM.dd}"
        template_name => "helm-chart-specialist"
        template => "/usr/share/logstash/templates/helm-chart-template.json"
        template_overwrite => true
      }

      # Security events to dedicated index
      if "security-event" in [tags] {
        elasticsearch {
          hosts => ["http://elasticsearch-external:9200"]
          index => "helm-chart-security-%{+YYYY.MM.dd}"
        }
      }

      # Audit events to compliance index
      if "audit-event" in [tags] {
        elasticsearch {
          hosts => ["http://elasticsearch-external:9200"]
          index => "helm-chart-audit-%{+YYYY.MM.dd}"
        }
      }

      # Performance metrics to dedicated index
      if "performance-metric" in [tags] {
        elasticsearch {
          hosts => ["http://elasticsearch-external:9200"]
          index => "helm-chart-performance-%{+YYYY.MM.dd}"
        }
      }

      # Business events to analytics index
      if "business-event" in [tags] {
        elasticsearch {
          hosts => ["http://elasticsearch-external:9200"]
          index => "helm-chart-business-%{+YYYY.MM.dd}"
        }
      }

      # Debug output (remove in production)
      stdout {
        codec => rubydebug
      }
    }

---
# Logstash Templates
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-templates
  namespace: elk-system
data:
  helm-chart-template.json: |
    {
      "index_patterns": ["helm-chart-specialist-*"],
      "template": {
        "settings": {
          "number_of_shards": 3,
          "number_of_replicas": 1,
          "refresh_interval": "5s",
          "index.lifecycle.name": "helm-logs-policy",
          "index.lifecycle.rollover_alias": "helm-chart-specialist"
        },
        "mappings": {
          "properties": {
            "@timestamp": { "type": "date" },
            "timestamp": { "type": "date" },
            "level": { "type": "keyword" },
            "message": { "type": "text", "analyzer": "standard" },
            "service": { "type": "keyword" },
            "version": { "type": "keyword" },
            "environment": { "type": "keyword" },
            "correlationId": { "type": "keyword" },
            "traceId": { "type": "keyword" },
            "spanId": { "type": "keyword" },
            "operation": { "type": "keyword" },
            "chartType": { "type": "keyword" },
            "chartName": { "type": "keyword" },
            "environment_target": { "type": "keyword" },
            "user": { "type": "keyword" },
            "duration": { "type": "long" },
            "status": { "type": "keyword" },
            "error": { "type": "text" },
            "tags": { "type": "keyword" },
            "metadata": { "type": "object" },
            "processed_at": { "type": "date" }
          }
        }
      }
    }

---
# Filebeat DaemonSet for log collection
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: filebeat
  namespace: elk-system
  labels:
    app: filebeat
spec:
  selector:
    matchLabels:
      app: filebeat
  template:
    metadata:
      labels:
        app: filebeat
    spec:
      serviceAccount: filebeat
      terminationGracePeriodSeconds: 30
      securityContext:
        runAsUser: 0
      containers:
      - name: filebeat
        image: docker.elastic.co/beats/filebeat:8.10.4
        args: [
          "-c", "/etc/filebeat.yml",
          "-e"
        ]
        env:
        - name: ELASTICSEARCH_HOST
          value: "elasticsearch-external"
        - name: ELASTICSEARCH_PORT
          value: "9200"
        - name: LOGSTASH_HOST
          value: "logstash"
        - name: LOGSTASH_PORT
          value: "5044"
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        volumeMounts:
        - name: config
          mountPath: /etc/filebeat.yml
          subPath: filebeat.yml
          readOnly: true
        - name: prospectors
          mountPath: /usr/share/filebeat/prospectors.d
          readOnly: true
        - name: data
          mountPath: /usr/share/filebeat/data
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlogs
          mountPath: /var/logs
          readOnly: true
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 200m
        securityContext:
          runAsUser: 0
      volumes:
      - name: config
        configMap:
          name: filebeat-config
      - name: prospectors
        configMap:
          name: filebeat-prospectors
      - name: data
        hostPath:
          path: /var/lib/filebeat-data
          type: DirectoryOrCreate
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlogs
        hostPath:
          path: /var/logs

---
# Filebeat Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
  namespace: elk-system
data:
  filebeat.yml: |
    filebeat.config:
      prospectors:
        path: /usr/share/filebeat/prospectors.d/*.yml
        reload.enabled: false

    processors:
    - add_cloud_metadata:
    - add_kubernetes_metadata:
        host: ${NODE_NAME}
        matchers:
        - logs_path:
            logs_path: "/var/log/containers/"

    output.logstash:
      hosts: ["${LOGSTASH_HOST}:${LOGSTASH_PORT}"]

    logging.level: info
    logging.to_files: true
    logging.files:
      path: /var/log/filebeat
      name: filebeat
      keepfiles: 7
      permissions: 0644

---
# Filebeat Prospectors
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-prospectors
  namespace: elk-system
data:
  kubernetes.yml: |
    - type: container
      paths:
        - /var/log/containers/*helm-chart*.log
        - /var/log/containers/*monitoring-web-service*.log
      processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
      fields:
        logtype: helm-chart-specialist
      fields_under_root: true

---
# ServiceAccount for Filebeat
apiVersion: v1
kind: ServiceAccount
metadata:
  name: filebeat
  namespace: elk-system

---
# ClusterRole for Filebeat
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: filebeat
rules:
- apiGroups: [""]
  resources:
  - nodes
  - namespaces
  - events
  - pods
  verbs: ["get", "list", "watch"]

---
# ClusterRoleBinding for Filebeat
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: filebeat
subjects:
- kind: ServiceAccount
  name: filebeat
  namespace: elk-system
roleRef:
  kind: ClusterRole
  name: filebeat
  apiGroup: rbac.authorization.k8s.io

---
# Network Policy for ELK Stack
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: elk-stack-netpol
  namespace: elk-system
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring-web-service
    - namespaceSelector:
        matchLabels:
          name: monitoring
    - namespaceSelector:
        matchLabels:
          name: elk-system
    ports:
    - protocol: TCP
      port: 9200  # Elasticsearch
    - protocol: TCP
      port: 5601  # Kibana
    - protocol: TCP
      port: 5044  # Logstash beats
    - protocol: TCP
      port: 9600  # Logstash API
  egress:
  - to: []
    ports:
    - protocol: TCP
      port: 443   # HTTPS
    - protocol: TCP
      port: 53    # DNS
    - protocol: UDP
      port: 53    # DNS

---
# Ingress for Kibana UI
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: kibana-ui
  namespace: elk-system
  labels:
    app: kibana
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
spec:
  ingressClassName: nginx
  rules:
  - host: kibana.monitoring-web-service.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: kibana
            port:
              number: 5601