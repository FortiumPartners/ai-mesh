# Advanced Auto-scaling Configuration
# Sprint 8 Task 8.3: Load balancing & auto-scaling
#
# Features:
# - Multi-metric Horizontal Pod Autoscaler (HPA)
# - Vertical Pod Autoscaler (VPA)
# - Custom metrics from CloudWatch
# - Predictive scaling with scheduled scaling
# - KEDA (Kubernetes Event-Driven Autoscaling)

---
# Advanced Horizontal Pod Autoscaler with multiple metrics
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: external-metrics-service-hpa-advanced
  namespace: fortium-metrics
  labels:
    app: external-metrics-service
    component: autoscaling
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: external-metrics-service
  minReplicas: 3
  maxReplicas: 50  # Increased for high load scenarios
  
  metrics:
  # CPU-based scaling
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 65  # More conservative for better performance
  
  # Memory-based scaling
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 75
  
  # Custom metrics: HTTP requests per second
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "50"  # Scale when > 50 RPS per pod
  
  # Custom metrics: API response time
  - type: Pods
    pods:
      metric:
        name: http_request_duration_p95
      target:
        type: AverageValue
        averageValue: "500m"  # Scale when P95 > 500ms
  
  # Custom metrics: Database connection pool utilization
  - type: Pods
    pods:
      metric:
        name: database_connection_pool_utilization
      target:
        type: AverageValue
        averageValue: "70"  # Scale when > 70% pool utilization
  
  # External metrics from CloudWatch: Queue depth
  - type: External
    external:
      metric:
        name: sqs_queue_messages_visible
        selector:
          matchLabels:
            queue: metrics-processing-queue
      target:
        type: AverageValue
        averageValue: "20"
  
  # External metrics: CloudWatch API errors
  - type: External
    external:
      metric:
        name: api_errors_per_minute
        selector:
          matchLabels:
            service: external-metrics
      target:
        type: AverageValue
        averageValue: "10"
  
  # External metrics: Active user sessions
  - type: External
    external:
      metric:
        name: active_user_sessions
        selector:
          matchLabels:
            service: external-metrics
      target:
        type: AverageValue
        averageValue: "100"  # Scale when > 100 sessions per pod
  
  # Scaling behavior configuration
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 minutes stabilization
      policies:
      - type: Percent
        value: 10        # Scale down max 10% at a time
        periodSeconds: 60
      - type: Pods
        value: 2         # Scale down max 2 pods at a time
        periodSeconds: 60
      selectPolicy: Min  # Use the most conservative policy
    scaleUp:
      stabilizationWindowSeconds: 60   # 1 minute stabilization
      policies:
      - type: Percent
        value: 100       # Scale up max 100% at a time for emergencies
        periodSeconds: 30
      - type: Pods
        value: 5         # Scale up max 5 pods at a time for rapid response
        periodSeconds: 30
      - type: Pods
        value: 10        # Emergency scaling for very high load
        periodSeconds: 60
      selectPolicy: Max  # Use the most aggressive policy

---
# Vertical Pod Autoscaler for resource optimization
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: external-metrics-service-vpa-advanced
  namespace: fortium-metrics
  labels:
    app: external-metrics-service
    component: autoscaling
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: external-metrics-service
  
  updatePolicy:
    updateMode: "Auto"  # Automatically apply recommendations
  
  resourcePolicy:
    containerPolicies:
    - containerName: external-metrics-service
      minAllowed:
        cpu: 100m
        memory: 256Mi
      maxAllowed:
        cpu: 4000m      # Increased for high-performance scenarios
        memory: 8Gi     # Increased for in-memory analytics
      controlledResources: ["cpu", "memory"]
      controlledValues: RequestsAndLimits
      mode: Auto
    - containerName: log-shipper  # If using sidecar
      minAllowed:
        cpu: 50m
        memory: 64Mi
      maxAllowed:
        cpu: 200m
        memory: 256Mi
      controlledResources: ["cpu", "memory"]
      controlledValues: RequestsAndLimits
      mode: Auto

---
# KEDA ScaledObject for event-driven autoscaling
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: external-metrics-service-keda
  namespace: fortium-metrics
  labels:
    app: external-metrics-service
    component: keda-autoscaling
spec:
  scaleTargetRef:
    name: external-metrics-service
  pollingInterval: 30   # Check metrics every 30 seconds
  cooldownPeriod: 300   # Wait 5 minutes before scaling down
  idleReplicaCount: 3   # Minimum replicas when no activity
  minReplicaCount: 3
  maxReplicaCount: 100  # Very high for extreme load scenarios
  
  triggers:
  # CloudWatch SQS Queue trigger
  - type: aws-cloudwatch
    metadata:
      namespace: AWS/SQS
      metricName: ApproximateNumberOfVisibleMessages
      dimensionName: QueueName
      dimensionValue: metrics-processing-queue
      targetValue: "20"
      minValue: "0"
      awsRegion: us-east-1
      identityOwner: pod
  
  # CloudWatch API Gateway trigger  
  - type: aws-cloudwatch
    metadata:
      namespace: AWS/ApiGateway
      metricName: Count
      dimensionName: ApiName
      dimensionValue: external-metrics-api
      targetValue: "1000"  # Scale when > 1000 requests/minute
      minValue: "0"
      awsRegion: us-east-1
      identityOwner: pod
  
  # CloudWatch ALB trigger
  - type: aws-cloudwatch
    metadata:
      namespace: AWS/ApplicationELB
      metricName: RequestCount
      dimensionName: LoadBalancer
      dimensionValue: app/external-metrics-alb/xyz123
      targetValue: "500"   # Scale when > 500 requests/minute
      minValue: "0"
      awsRegion: us-east-1
      identityOwner: pod
  
  # Redis Queue trigger
  - type: redis
    metadata:
      address: redis-cluster.fortium-metrics.svc.cluster.local:6379
      listName: metrics:processing:queue
      listLength: "10"
      enableTLS: "true"
  
  # Prometheus metrics trigger
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc.cluster.local:9090
      metricName: http_requests_per_second
      threshold: '50'
      query: rate(http_requests_total{service="external-metrics-service"}[2m])
  
  # Datadog trigger (if using Datadog)
  - type: datadog
    metadata:
      query: avg:external_metrics.api.requests_per_second{service:external-metrics}
      queryValue: "75"
      age: "60"

---
# Predictive Horizontal Pod Autoscaler (if using Predictive VPA/HPA addon)
apiVersion: autoscaling.gke.io/v1beta1
kind: MultidimPodAutoscaler
metadata:
  name: external-metrics-service-predictive-hpa
  namespace: fortium-metrics
  labels:
    app: external-metrics-service
    component: predictive-autoscaling
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: external-metrics-service
  
  constraints:
    global:
      minReplicas: 3
      maxReplicas: 50
    container:
      external-metrics-service:
        requests:
          cpu:
            min: 100m
            max: 2000m
          memory:
            min: 256Mi
            max: 4Gi
  
  goals:
    metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          averageUtilization: 65
    - type: Resource
      resource:
        name: memory
        target:
          averageUtilization: 75
  
  policy:
    mode: "Forecast"  # Use predictive scaling
    forecastModel: "ml-based"
    forecastWindow: "24h"

---
# Scheduled scaling for predictable load patterns
apiVersion: batch/v1
kind: CronJob
metadata:
  name: external-metrics-service-scheduled-scaler
  namespace: fortium-metrics
  labels:
    app: external-metrics-service
    component: scheduled-scaling
spec:
  # Scale up for business hours (9 AM UTC)
  schedule: "0 9 * * 1-5"  # Weekdays at 9 AM
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: external-metrics-scaler
          restartPolicy: OnFailure
          containers:
          - name: scaler
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "Scaling up for business hours..."
              kubectl patch hpa external-metrics-service-hpa-advanced -p '{"spec":{"minReplicas":5}}'
              kubectl patch hpa external-metrics-service-hpa-advanced -p '{"spec":{"maxReplicas":30}}'
              echo "Scaling configuration updated for business hours"

---
# Scale down for off hours (6 PM UTC)
apiVersion: batch/v1
kind: CronJob
metadata:
  name: external-metrics-service-scheduled-scaler-down
  namespace: fortium-metrics
  labels:
    app: external-metrics-service
    component: scheduled-scaling
spec:
  schedule: "0 18 * * 1-5"  # Weekdays at 6 PM
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: external-metrics-scaler
          restartPolicy: OnFailure
          containers:
          - name: scaler
            image: bitnami/kubectl:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "Scaling down for off hours..."
              kubectl patch hpa external-metrics-service-hpa-advanced -p '{"spec":{"minReplicas":3}}'
              kubectl patch hpa external-metrics-service-hpa-advanced -p '{"spec":{"maxReplicas":15}}'
              echo "Scaling configuration updated for off hours"

---
# Service Account for scheduled scaling
apiVersion: v1
kind: ServiceAccount
metadata:
  name: external-metrics-scaler
  namespace: fortium-metrics

---
# Role for scaling operations
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: fortium-metrics
  name: external-metrics-scaler-role
rules:
- apiGroups: ["autoscaling"]
  resources: ["horizontalpodautoscalers"]
  verbs: ["get", "patch", "update"]
- apiGroups: ["apps"]
  resources: ["deployments", "deployments/scale"]
  verbs: ["get", "patch", "update"]

---
# RoleBinding for scaling operations
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: external-metrics-scaler-rolebinding
  namespace: fortium-metrics
subjects:
- kind: ServiceAccount
  name: external-metrics-scaler
  namespace: fortium-metrics
roleRef:
  kind: Role
  name: external-metrics-scaler-role
  apiGroup: rbac.authorization.k8s.io

---
# PodMonitor for advanced metrics collection
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: external-metrics-service-podmonitor
  namespace: fortium-metrics
  labels:
    app: external-metrics-service
    component: monitoring
spec:
  selector:
    matchLabels:
      app: external-metrics-service
  podMetricsEndpoints:
  - port: metrics
    path: /metrics
    interval: 15s
    scrapeTimeout: 10s
  - port: http
    path: /api/v1/metrics/prometheus
    interval: 30s
    scrapeTimeout: 15s

---
# PrometheusRule for autoscaling alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: external-metrics-service-scaling-alerts
  namespace: fortium-metrics
  labels:
    app: external-metrics-service
    component: alerting
spec:
  groups:
  - name: external-metrics-scaling
    rules:
    - alert: HighCPUUtilization
      expr: avg(rate(container_cpu_usage_seconds_total{pod=~"external-metrics-service-.*"}[5m])) > 0.8
      for: 2m
      labels:
        severity: warning
        component: autoscaling
      annotations:
        summary: "High CPU utilization detected"
        description: "CPU utilization is {{ $value }}% for 2 minutes"
    
    - alert: HighMemoryUtilization
      expr: avg(container_memory_usage_bytes{pod=~"external-metrics-service-.*"} / container_spec_memory_limit_bytes) > 0.85
      for: 2m
      labels:
        severity: warning
        component: autoscaling
      annotations:
        summary: "High memory utilization detected"
        description: "Memory utilization is {{ $value }}% for 2 minutes"
    
    - alert: HighRequestRate
      expr: sum(rate(http_requests_total{service="external-metrics-service"}[5m])) > 1000
      for: 1m
      labels:
        severity: info
        component: autoscaling
      annotations:
        summary: "High request rate detected"
        description: "Request rate is {{ $value }} requests/second"
    
    - alert: ScalingEventFrequent
      expr: increase(kube_hpa_status_current_replicas{hpa="external-metrics-service-hpa-advanced"}[10m]) > 5
      for: 0m
      labels:
        severity: info
        component: autoscaling
      annotations:
        summary: "Frequent scaling events detected"
        description: "HPA has scaled {{ $value }} times in the last 10 minutes"